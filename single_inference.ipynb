{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fbe02499",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbe02499",
        "outputId": "8bc68391-a135-4c67-dc75-562601c4ba22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RINE-extended'...\n",
            "remote: Enumerating objects: 471, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 471 (delta 2), reused 2 (delta 0), pack-reused 461 (from 2)\u001b[K\n",
            "Receiving objects: 100% (471/471), 100.54 MiB | 17.66 MiB/s, done.\n",
            "Resolving deltas: 100% (297/297), done.\n",
            "Updating files: 100% (442/442), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MarkBridge11/RINE-extended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57320b29",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "57320b29"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/RINE-extended')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2acd2c4f",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acd2c4f",
        "outputId": "5f6ed07e-c1eb-43c2-81d8-a2a21be4dcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-zbybklt8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-zbybklt8\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.9.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia)\n",
            "  Downloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.1->kornia) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.2)\n",
            "Downloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=68ab70446602b7b02a043db516be527b7dfdc4ab724a2d5196adf6a76f73e75f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7oz801ng/wheels/35/3e/df/3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n",
            "Successfully built clip\n",
            "Installing collected packages: kornia_rs, ftfy, kornia, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1 kornia-0.8.1 kornia_rs-0.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-image imageio opencv-python kornia git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "62f107c5",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "62f107c5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from src.utils import get_transforms, get_our_trained_model\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fe5677a9",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe5677a9",
        "outputId": "21eaf19c-131e-466f-b2c8-92114f5233bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 890M/890M [00:12<00:00, 72.7MiB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_, transforms, _ = get_transforms()\n",
        "model = get_our_trained_model(ncls=\"ldm\", device=device)\n",
        "model.to(device).eval();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_path = \"/content/RINE-extended/demo/aadlygmazf.jpg\"\n",
        "real_image = Image.open(real_path).convert(\"RGB\")\n",
        "real_tensor = transforms(real_image).unsqueeze(0).to(device)\n",
        "real_logit = model(real_tensor)[0]\n",
        "real_probability = torch.sigmoid(real_logit)\n",
        "print(\n",
        "    f\"real image - prob. to be fake: {real_probability.detach().cpu().numpy()[0][0]*100:1.1f}%\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-7FHdVLHH6h",
        "outputId": "3a26e7a3-e3e1-4eb8-851c-b64d611c21f6"
      },
      "id": "K-7FHdVLHH6h",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real image - prob. to be fake: 35.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# g has shape [tokens, blocks, dim]\n",
        "g = torch.stack([h.output for h in model.hooks], dim=2)[0]  # [tokens, blocks, dim]\n",
        "\n",
        "# softmax weights [1, blocks, dim]\n",
        "weights = torch.softmax(model.alpha, dim=1)[0]\n",
        "\n",
        "# elementwise product before summation\n",
        "contrib = g * weights  # [tokens, blocks, dim]\n",
        "\n",
        "# sum across dim (feature dimension) → patch/block contribution\n",
        "contrib_map = contrib.sum(-1)  # [tokens, blocks]\n",
        "\n",
        "# average over blocks if you want a single score per token\n",
        "token_scores = contrib_map.mean(-1)  # [tokens]"
      ],
      "metadata": {
        "id": "5sKbr28uL_ih"
      },
      "id": "5sKbr28uL_ih",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_size = int(token_scores[:-1].shape[0] ** 0.5)  # exclude CLS\n",
        "heatmap = token_scores[:-1].reshape(grid_size, grid_size).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "0qHBocUUMunf"
      },
      "id": "0qHBocUUMunf",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_token_importance(model, x):\n",
        "    with torch.no_grad():\n",
        "        _ = model.clip.encode_image(x)  # run CLIP forward to fill hooks\n",
        "        g = torch.stack([h.output for h in model.hooks], dim=2)[0]  # [tokens, blocks, dim]\n",
        "        g = model.proj1(g.float())  # same as in forward\n",
        "\n",
        "    # apply alpha weights\n",
        "    weights = F.softmax(model.alpha, dim=1)[0]  # [blocks, dim]\n",
        "    contrib = g * weights  # [tokens, blocks, dim]\n",
        "\n",
        "    # sum across feature dimension → relevance per token/block\n",
        "    contrib_map = contrib.sum(-1)  # [tokens, blocks]\n",
        "\n",
        "    # average over blocks → single importance score per token\n",
        "    token_scores = contrib_map.mean(-1)  # [tokens]\n",
        "\n",
        "    return token_scores.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "g-qT-wV9Ok4v"
      },
      "id": "g-qT-wV9Ok4v",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_heatmap(token_scores, image_size=(224,224)):\n",
        "    n_tokens = token_scores.shape[0]\n",
        "    grid_size = int(np.sqrt(n_tokens - 1))  # exclude CLS token\n",
        "    patch_scores = token_scores[1:].reshape(grid_size, grid_size)  # drop CLS\n",
        "\n",
        "    # normalize 0–1\n",
        "    patch_scores = (patch_scores - patch_scores.min()) / (patch_scores.max() - patch_scores.min() + 1e-6)\n",
        "\n",
        "    # upscale to image size\n",
        "    heatmap = cv2.resize(patch_scores, image_size, interpolation=cv2.INTER_CUBIC)\n",
        "    return heatmap"
      ],
      "metadata": {
        "id": "UsfzKehVN88k"
      },
      "id": "UsfzKehVN88k",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_heatmap(img, heatmap, alpha=0.5):\n",
        "    cmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
        "    cmap = cv2.cvtColor(cmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_np = np.array(img)\n",
        "    overlay = cv2.addWeighted(img_np, 1-alpha, cmap, alpha, 0)\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "L55CLhiBOOvI"
      },
      "id": "L55CLhiBOOvI",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get token importance\n",
        "token_scores = get_token_importance(model, real_tensor)\n",
        "\n",
        "# make heatmap\n",
        "heatmap = tokens_to_heatmap(token_scores, image_size=real_image.size)\n",
        "\n",
        "# overlay\n",
        "overlay_heatmap(real_image, heatmap, alpha=0.5)"
      ],
      "metadata": {
        "id": "jpYy8pXWO6js",
        "outputId": "105d07a3-1c5c-4a58-b606-6f39a2f5c08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "id": "jpYy8pXWO6js",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation minimum which has no identity",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2427664343.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# make heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_to_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# overlay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2675335740.py\u001b[0m in \u001b[0;36mtokens_to_heatmap\u001b[0;34m(token_scores, image_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# normalize 0–1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpatch_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatch_scores\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpatch_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatch_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpatch_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# upscale to image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     47\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7181e560",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "7181e560"
      },
      "outputs": [],
      "source": [
        "# fake_path = \"/content/RINE-extended/demo/zzrybysskm.jpg\"\n",
        "# fake_image = Image.open(fake_path).convert(\"RGB\")\n",
        "# fake_tensor = transforms(fake_image).unsqueeze(0).to(device)\n",
        "# fake_logit = model(fake_tensor)[0]\n",
        "# fake_probability = torch.sigmoid(fake_logit)\n",
        "# print(\n",
        "#     f\"fake image - prob. to be fake: {fake_probability.detach().cpu().numpy()[0][0]*100:1.1f}%\"\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}